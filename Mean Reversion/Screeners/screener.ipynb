{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements:\n",
    "# Install the required libraries using the following commands:\n",
    "# pip install yfinance pandas numpy statsmodels \n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime, timedelta\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "import requests\n",
    "\n",
    "def is_valid_ticker(ticker):\n",
    "    try:\n",
    "        data = yf.download(ticker, period='1d')\n",
    "        return not data.empty\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def get_ticker_from_name(input_string):\n",
    "    if is_valid_ticker(input_string):\n",
    "        return input_string\n",
    "    else:\n",
    "        try:\n",
    "            res = requests.get(f'https://www.alphavantage.co/query?function=SYMBOL_SEARCH&keywords={input_string}&apikey=SZ83NMER0LTRQCI5')\n",
    "            response = res.json()\n",
    "            return response[\"bestMatches\"][0][\"1. symbol\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Could not find ticker for {input_string}: {e}\")\n",
    "            return None\n",
    "\n",
    "def get_price_data(tickers, start_date, end_date):\n",
    "    data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']\n",
    "    return data\n",
    "\n",
    "def calculate_half_life(spread):\n",
    "    spread_lag = spread.shift(1)\n",
    "    spread_lag.iloc[0] = spread_lag.iloc[1]\n",
    "    spread_ret = spread - spread_lag\n",
    "    spread_lag = sm.add_constant(spread_lag)\n",
    "    model = sm.OLS(spread_ret, spread_lag).fit()\n",
    "    halflife = -np.log(2) / model.params[1]\n",
    "    return halflife\n",
    "\n",
    "def johansen_test(data, significance_level=0.10):\n",
    "    result = coint_johansen(data, det_order=0, k_ar_diff=1)\n",
    "    trace_stat = result.lr1\n",
    "    if significance_level == 0.10:\n",
    "        trace_critical_values = result.cvt[:, 0]  # 90% confidence level\n",
    "    elif significance_level == 0.05:\n",
    "        trace_critical_values = result.cvt[:, 1]  # 95% confidence level\n",
    "    elif significance_level == 0.01:\n",
    "        trace_critical_values = result.cvt[:, 2]  # 99% confidence level\n",
    "    else:\n",
    "        raise ValueError(\"significance_level must be 0.10, 0.05, or 0.01\")\n",
    "    return trace_stat, trace_critical_values\n",
    "\n",
    "def find_cointegrated_pairs(data):\n",
    "    n = data.shape[1]\n",
    "    keys = data.columns\n",
    "    pairs = []\n",
    "    half_lives = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            S1 = data[keys[i]]\n",
    "            S2 = data[keys[j]]\n",
    "            combined_data = pd.concat([S1, S2], axis=1)\n",
    "            trace_stat, trace_critical_values = johansen_test(combined_data)\n",
    "            if trace_stat[0] > trace_critical_values[0]:  # Test for cointegration\n",
    "                pairs.append((keys[i], keys[j]))\n",
    "                spread = S1 - S2\n",
    "                half_life = calculate_half_life(spread)\n",
    "                half_lives.append(half_life)\n",
    "    \n",
    "    return pairs, half_lives\n",
    "\n",
    "def display_results(pairs, half_lives):\n",
    "    results = pd.DataFrame({\n",
    "        'Pair': pairs,\n",
    "        'Half-life': half_lives\n",
    "    })\n",
    "    results.sort_values(by='Half-life', inplace=True)\n",
    "    print(results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while True:\n",
    "    try:\n",
    "        start_date = \"2023-01-01\"\n",
    "        end_date = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    except:\n",
    "        continue\n",
    "    break\n",
    "asset_names = [\"NIO\", \"BYND\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'nvda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ticker_from_name(\"nvda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "tickers = []\n",
    "for name in asset_names:\n",
    "    ticker = get_ticker_from_name(name)\n",
    "    if ticker:\n",
    "        tickers.append(ticker)\n",
    "if len(tickers) < 2:\n",
    "    print(\"Assets not found! \\n\")\n",
    "    quit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  2 of 2 completed\n",
      "Cointegrated pairs found: 0\n",
      "Empty DataFrame\n",
      "Columns: [Pair, Half-life]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "price_data = get_price_data(tickers, start_date, end_date)\n",
    "price_data.dropna(inplace=True)\n",
    "\n",
    "cointegrated_pairs, half_lives = find_cointegrated_pairs(price_data)\n",
    "print('Cointegrated pairs found:', len(cointegrated_pairs))\n",
    "display_results(cointegrated_pairs, half_lives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = price_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = data.shape[1]\n",
    "keys = data.columns\n",
    "pairs = []\n",
    "half_lives = []\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i+1, n):\n",
    "        S1 = data[keys[i]]\n",
    "        S2 = data[keys[j]]\n",
    "        combined_data = pd.concat([S1, S2], axis=1)\n",
    "        trace_stat, trace_critical_values = johansen_test(combined_data)\n",
    "        if trace_stat[0] > trace_critical_values[0]:  # Test for cointegration\n",
    "            pairs.append((keys[i], keys[j]))\n",
    "            spread = S1 - S2\n",
    "            half_life = calculate_half_life(spread)\n",
    "            half_lives.append(half_life)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.57388641, 1.27496334])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.4294,  2.7055])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_critical_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
